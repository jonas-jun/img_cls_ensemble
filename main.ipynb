{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import ImageFolderDataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import albumentations.augmentations as Aaug\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 384\n",
    "transform = A.Compose([\n",
    "                A.Resize(input_size, input_size, interpolation=cv2.INTER_CUBIC),\n",
    "                A.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "train_set = ImageFolderDataset(data_dir='dataset/seg_train', transform=transform)\n",
    "test_set = ImageFolderDataset(data_dir='dataset/seg_test', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> TRAIN SET\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
      "{'buildings': 2191, 'forest': 2271, 'glacier': 2404, 'mountain': 2512, 'sea': 2274, 'street': 2382}\n",
      ">> TEST SET\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
      "{'buildings': 437, 'forest': 474, 'glacier': 553, 'mountain': 525, 'sea': 510, 'street': 501}\n"
     ]
    }
   ],
   "source": [
    "print('>> TRAIN SET')\n",
    "print(train_set.classes)\n",
    "print(train_set.cls_dict)\n",
    "print(train_set.count_dict)\n",
    "print('>> TEST SET')\n",
    "print(test_set.classes)\n",
    "print(test_set.cls_dict)\n",
    "print(test_set.count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 512\n",
    "n_workers = 8\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=n_workers)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RN50x16\n",
      "model.visual.input_resolution: 384\n",
      "model.visual.output_dim      : 768\n"
     ]
    }
   ],
   "source": [
    "from model import CLIPextractor\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "seed = 42\n",
    "clip = CLIPextractor(pretrain_name='RN50x16')\n",
    "regr = SVC(kernel='rbf', random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- CLIP: 768 dim feature extraction with eval mode\n",
    "- SVM: training with features and labels\n",
    "- SVM model save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def feature_extract(model, loader, device):\n",
    "    model.to(device)\n",
    "    _ = model.eval()\n",
    "\n",
    "    features = torch.tensor([])\n",
    "    labels = list()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            image, label, _ = batch\n",
    "            image = image.to(device)\n",
    "            feature = model(image).detach().cpu()\n",
    "            features = torch.cat([features, feature])\n",
    "            labels += label\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29abad8c915487e89208a2bc14685d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98ccc8258ce4b998a35a1bf398c0601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_features, train_labels = feature_extract(model=clip, loader=train_loader, device=device)\n",
    "test_features, test_labels = feature_extract(model=clip, loader=test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_regressor.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "regr_model = 'SVM_regressor.joblib'\n",
    "regr.fit(np.array(train_features), np.array(train_labels))\n",
    "dump(regr, regr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = load(regr_model)\n",
    "predicted = regr.predict(np.array(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> TEST STATISTICS\n",
      "acc 0.9506666666666667\n",
      "precision 0.9514470576485543\n",
      "recall 0.9519404223393879\n",
      "f1 score 0.9515754191565385\n",
      "confusion_matrix\n",
      "[[412   0   0   0   2  23]\n",
      " [  0 473   0   0   0   1]\n",
      " [  0   2 495  50   5   1]\n",
      " [  1   3  30 488   3   0]\n",
      " [  2   0   3   1 504   0]\n",
      " [ 20   0   0   0   1 480]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('>> TEST STATISTICS')\n",
    "print('acc', accuracy_score(y_true=test_labels, y_pred=predicted))\n",
    "print('precision', precision_score(y_true=test_labels, y_pred=predicted, average='macro'))\n",
    "print('recall', recall_score(y_true=test_labels, y_pred=predicted, average='macro'))\n",
    "print('f1 score', f1_score(y_true=test_labels, y_pred=predicted, average='macro'))\n",
    "print('confusion_matrix')\n",
    "print(confusion_matrix(y_true=test_labels, y_pred=predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('scoring')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0ba4ca3ef69bf738ca048d2b51826cb94db64964450ddd8d5787a68cf2064e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
